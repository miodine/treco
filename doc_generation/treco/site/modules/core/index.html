<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><link rel="canonical" href="https://github.com/miodine/treco/modules/core/" />
      <link rel="shortcut icon" href="../../img/favicon.ico" />
    <title>forecasts - treco</title>
    <link rel="stylesheet" href="../../css/theme.css" />
    <link rel="stylesheet" href="../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "forecasts";
        var mkdocs_page_input_path = "modules/core.md";
        var mkdocs_page_url = "/miodine/treco/modules/core/";
      </script>
    
    <script src="../../js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../.." class="icon icon-home"> treco
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../..">Home</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../user_guide/">User Guide</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../../api_reference/">API</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Modules</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="./">core</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="./">forecasts</a>
    <ul class="current">
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../indicators/">indicators</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../markets/">markets</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../extras/">extras</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../..">treco</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../.." class="icon icon-home" alt="Docs"></a> &raquo;</li>
          <li>Modules &raquo;</li>
      <li>forecasts</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="necessary-imports">Necessary imports</h1>
<p>import pandas as pd
import requests
from bs4 import BeautifulSoup
import json</p>
<h1 id="common-constants">Common constants</h1>
<p>HEADERS = {"User-Agent": "TrecoBot/1.0"}        # The request header.</p>
<h1 id="the-main-website-url-from-which-we-scrape-the-data">The main website URL from which we scrape the data.</h1>
<p>MAIN_URL = "https://tradingeconomics.com/"</p>
<p>'''</p>
<h1 id="trecocore">treco.core</h1>
<h2 id="module-description">MODULE DESCRIPTION</h2>
<p>The module contains all core utilities and functions 
of the package related to data extraction from 
tradingeconomics. </p>
<p>The functions presented here are NOT meant to be called
by the user. </p>
<p>'''</p>
<p>def __format_dataframe(dataframe: pd.DataFrame, fmt: str):
    '''
    ## Description
    Helper function to change the format of a dataframe. </p>
<pre><code>By default, data handling is meant to be using Pandas' dataframe, but 
if needed - some other format can be used.

## Supported formats: 
* DataFrame -  in-program data exchange
* json      -  file handling/in-program data exchange
* csv       -  file handling 
* dict      -  in-program data exchange
* html      -  file handling 
* pickle    -  file handling
* latex     -  file handling / string manipulation

## Parameters:
dataframe :  dataframe to-be converted.
fmt       :  target format for the df to be converted, as a string. Case insensitive.

'''

fmt = fmt.lower()

if fmt == "json":
    return dataframe.to_json()
elif fmt == "csv":
    return dataframe.to_csv()
elif fmt == "dict":
    return dataframe.to_dict()
elif fmt == "html":
    return dataframe.to_html()
elif fmt == "numpy" or "np":
    return dataframe.to_numpy()
elif fmt == "pickle":
    return dataframe.to_pickle()
elif fmt == "latex":
    return dataframe.to_latex()
else:
    return dataframe
</code></pre>
<p>def get_data_from_stream(begin=0, size=1, country="NULL", category="NULL") -&gt; list:
    '''
    ## Description</p>
<pre><code>The function requests and receives the data directly from news stream back-end endpoint.

## Parameters

begin : initial index of the news to be scraped. The news are ordered always from the newest (index == 0) to the oldest (index == len(database))
size  : number of news to be scraped. (max == 100)

## Returns

result_json : list of dictionaries constructed on the basis of JSON response.

## Notes

It is a very simple function, manipulating the get request string.

It's capabilities are limited by built-in safety mechanisms such as this one -  the maximum amount of news to be scraped cannot 
exceed 100 news in a single querry. To obtain more (consecutive) news, for example 300, one would have to:

1. Set index to 0
2. Set the size to 100 
3. Scrape the data from 0 to 0+100 indices, then again...
3. Set the beginning index to 100 (hundreth scraped news)
4. Set the size to 100 (max)
5. Scrape the data - from 100 to 100+100

'''

headers = HEADERS
stream_url = "https://tradingeconomics.com/ws/stream.ashx"

stream_get_args = "?start={begin}&amp;size={size}".format(
    begin=begin, size=size)
if country != "NULL":
    stream_get_args += "c={}".format(country.lower().replace(" ", "+"))
if country != "NULL":
    stream_get_args += "i={}".format(category.lower().replace(" ", "+"))

url = stream_url + stream_get_args

resp = requests.get(url, headers=headers)

soup = BeautifulSoup(resp.content, "html.parser", from_encoding="utf-8")

result_json = json.loads(soup.text.encode("utf-8", "ignore"))

return result_json
</code></pre>
<p>def get_data_from_tables(url: str) -&gt; list:
    '''
    ## Description</p>
<pre><code>Function allowing to obtain data from the tables presented on the website.

The function finds all the tables in given page, downloads its contents, 
and returns them in the form of list of dataframes (each dataframe represent different table).

## Parameters 
url : address from which we're scraping the data

## Returns 
df_tables_list : list of dataframes

'''

headers = HEADERS

response = requests.get(url=url, headers=headers)
soup = BeautifulSoup(response.content, "html.parser")

tables = soup.find_all("table", "table")

df_tables_list = []

for table in tables:
    df_table = pd.read_html(str(table))
    df_tables_list.append(df_table[0])

return df_tables_list
</code></pre>
<p>def scrape_specific_tables(server_path, fmt):
    '''
    ## Description </p>
<pre><code>Encapsulation of some of the utilities used by 
the other modules, for scraping data from tables.

## Params
server_path : hard-coded part of the URL adres with presented tables
fmt         : format of the resulting querry

## Returns
dataframe_list

'''

url = MAIN_URL + server_path
dataframe_list = get_data_from_tables(url)
for dataframe in dataframe_list:
    __format_dataframe(dataframe=dataframe, fmt=fmt)

return dataframe_list
</code></pre>
<p>def get_data_from_lists(url: str, as_list=False):
    '''
    ## Description</p>
<pre><code>Function allowing to obtain data from the lists presented on the website.

The function finds all the list in given page, downloads its contents, 
and returns them.

## Parameters 
url : address from which we're scraping the data
as_list : if True -&gt; the returned value is list of dictionaries. Otherwise it's a dictionary of dictionaries.

## Returns 
df_return : dictionary of dictionaires or list of dictionaries depending on - as_list parameter

'''

headers = HEADERS
response = requests.get(url=url, headers=headers)
soup = BeautifulSoup(response.content, "html.parser")

lists = soup.find_all("ul", {"class": "list-unstyled"})

df_return = {}
if as_list:
    df_return = []

for list_ in lists:

    list_contents = list_.find_all("li")
    df_list_contents = {}
    key = ""

    for list_item in list_contents:
        a = list_item.find("a")
        if a is not None:
            df_list_contents[list_item.text] = a.get("href")
        else:
            key = list_item.text
    if as_list == True:
        df_return.append([key, df_list_contents])
    else:
        df_return[key] = df_list_contents

return df_return
</code></pre>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="./" class="btn btn-neutral float-left" title="core"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../indicators/" class="btn btn-neutral float-right" title="indicators">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="./" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../indicators/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme_extra.js" defer></script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
